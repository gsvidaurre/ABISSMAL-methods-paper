---
title: "Video validation analysis 5: Behavioral inferences"
author: "Grace Smith-Vidaurre"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

*Purpose of coarse-grained behavioral inferences*: Ask how well the integrated dataset of movement sensors scored the TYPE of activity detected. This is a finer-grained validation to ask how well behavioral scores associated with the video recording events match between the two methods. Check out my notes above that detail expectations - there will be more scores per video recording event using the manual method. The ABISSMAL functions also are currently designed to identify discrete behavioral events in a coarse-grained way, rather than longer sequences of these dicrete events. Therefore, the analyses below focus on asking how often each type of behavior was identified per unique video recording event per method, rather than comparing sequences of behavioral scores.

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, messsage = FALSE)

```

Load packages and set paths.
```{r package and paths}

# Clean the global environment
rm(list = ls())

X <- c("tidyverse", "pbapply", "data.table", "tidyquant")

# Install the packages in X if not already installed
is_installed <- function(p) is.element(p, installed.packages()[,1])

invisible(lapply(1:length(X), function(x){
  if(!is_installed(X[x])){
    install.packages(X[x], repos = "http://lib.stat.cmu.edu/R/CRAN")
  }
}))

invisible(lapply(X, library, character.only = TRUE))

# Overall path: contains the aggregated BORIS spreadsheet in wide format across all video recording events
path <- "~/Desktop/ABISSMAL_validation_data"

# Path to the combined raw movement sensor data
sensor_path <- file.path(path, "raw_combined")

# Initialize a folder where we will save the indexed raw data for the validation analyses
indexed_dir <- "indexed_labeled_data"
indexed_path <- file.path(path, indexed_dir)

# Create this folder if it doesn't already exist
if(!dir.exists(indexed_path)){
  dir.create(indexed_path)
}

# Initialize the GitHub repo path, which holds a .csv file of a subsample of video file names used for code development
git_path <- "~/Desktop/GitHub_repos/ABISSMAL-methods-paper/Code"

seed <- 888

```


5. BEHAVIORAL INFERENCE: Next, ask how well the integrated dataset of movement sensors scored the TYPE of activity detected. This is a finer-grained validation to ask how well behavioral scores associated with the video recording events match between the two methods. Check out my notes above that detail expectations - there will be more scores per video recording event using the manual method. The ABISSMAL functions also are currently designed to identify discrete behavioral events in a coarse-grained way, rather than longer sequences of these dicrete events. Therefore, the analyses below focus on asking how often each type of behavior was identified per unique video recording event per method, rather than comparing sequences of behavioral scores.

For the analysis below, we want to know how often ABISSMAL and manual scoring picked up the same behavior in association with a given video recording event. Here we will compare the 4 categories of coarse-grained behaviors identified by both methods: INSC, PERC, ENTR, EXIT. We will also focus on scoring of only a single behavior at a time here.

**True positive** = the same behavior was detected by both ABISSMAL and manual scoring.

**False negative** = ABISSMAL did not detect the same behavior that was detected by the manual scoring. We cannot detect a true lack of detections by ABISSMAL (e.g. no behavioral score at all), since this validation analysis relies on the same videos recorded by motion detection to compare scoring methods, and all of these video recordings are associated with an automated behavioral inference by default.

**False positive** = ABISSMAL detected a different behavior from the manual scoring, or the manual scoring did not detect any birds (NOBR).

**True negative** = neither ABISSMAL nor manual scoring detect the given behavior. We cannot calculate true negatives (e.g. no behavioral scores at all) for the same reasons as above with false negatives.

Overall, we can calculate the precision, sensitivity, and specificity of detecting types of behaviors. Note that the false negatives and false positives are not mutually exclusive, although here the false positive calculations will take the NOBR manual scoring into account (so the false positives and negatives will not be exactly the same).
```{r}

# First we need to condense the behavioral inferences from automated scoring into a single column, again
auto_scoring5 <- auto_scoring_extraAssignedVids %>%
  dplyr::mutate(
    perching_inference = ifelse(!is.na(perching_rfid_start) | !is.na(perching_outer_irbb_start) | !is.na(perching_inner_irbb_start), "perching", NA)) %>% 
  dplyr::mutate(
    inferences = paste(direction_scored, inferredMovement_Location, perching_inference, sep = "-")
  )

glimpse(auto_scoring5)
# View(auto_scoring5)

table(auto_scoring5$inferences)

# no perching events represented here with this video subsample:

# entrance-container_entrance-NA      ### this is an entrance or ENTR
#                              6 
# exit-container_entrance-NA          ### this is an exit or EXIT
#                              3 
# NA-inside_container-NA              ### this is inside_container or INSC
#                             44 

# Will need to add back perching events for the full dataset (currently that inference is NA here)
auto_scoring5 <- auto_scoring5 %>% 
  dplyr::mutate(
    comb_behav_inf = ifelse(grepl("^entrance-|-entrance", inferences), "ENTR", inferences),
    comb_behav_inf = ifelse(grepl("^exit-|-exit", comb_behav_inf), "EXIT", comb_behav_inf),
    comb_behav_inf = ifelse(grepl("inside_container", comb_behav_inf), "INSC", comb_behav_inf),
    comb_behav_inf = ifelse(grepl("perch", comb_behav_inf), "PERC", comb_behav_inf)
  )

# Looks good
table(auto_scoring5$inferences)
table(auto_scoring5$comb_behav_inf)
glimpse(auto_scoring2)

```

Then we need to condense the automated scoring and the manual scoring data frame to have a single row per video.
```{r}

# View(manual_scoring_nm)
names(manual_scoring_nm)

# Get one row of behavioral labels per video recording event
manual_table <- manual_scoring_nm %>% 
  group_by(unmasked_video_file) %>%
  # Create a unique row identifier within videos
  dplyr::mutate(
    row_id = row_number()
  ) %>% 
  ungroup() %>% 
  # View()
  dplyr::select(row_id, unmasked_video_file, Behavior) %>% 
  pivot_wider(names_from = unmasked_video_file, values_from = Behavior) %>% 
  t()

auto_table <- auto_scoring5 %>% 
  group_by(assigned_recording_event) %>%
  # Create a unique row identifier within videos
  dplyr::mutate(
    row_id = row_number()
  ) %>% 
  ungroup() %>% 
  # View()
  dplyr::select(row_id, assigned_recording_event, comb_behav_inf) %>% 
  pivot_wider(names_from = assigned_recording_event, values_from = comb_behav_inf) %>% 
  t()

# View(auto_scoring2)

# View(auto_table)
# View(manual_table)

```

Calculate the true and false positives, and the true and false negatives.
```{r}

# Looks good
length(unique(auto_scoring5$assigned_recording_event))
length(unique(manual_scoring_nm$unmasked_video_file))

# Iterate over all the unique videos included in the automated and manual scoring tables
unique_videos <- unique(manual_scoring_nm$unmasked_video_file)
unique_videos

glimpse(auto_table)
glimpse(manual_table)

behavior_labels <- c("PERC", "ENTR", "EXIT", "INSC")
no_behavior_label <- "NOBR"

# i <- 2
# n <- 2

tp_fp_tn_fn <- data.table::rbindlist(pblapply(1:length(unique_videos), function(i){
  
  # Get unique behavioral scores for the given unique recording event from summarized tables of both scoring methods
  auto_scores <- unique(auto_table[grep(unique_videos[i], dimnames(auto_table)[[1]]), ])
  auto_scores <- auto_scores[!is.na(auto_scores)]
  
  manual_scores <- unique(manual_table[grep(unique_videos[i], dimnames(manual_table)[[1]]), ])
  manual_scores <- manual_scores[!is.na(manual_scores)]
  
  # auto_scores
  manual_scores
  
  # Iterate over the activity labels
  tmp_res <- data.table::rbindlist(lapply(1:length(behavior_labels), function(n){
    
    # Convert scores to Boolean using the activity labels
    auto_a <- ifelse(any(behavior_labels[n] %in% auto_scores), TRUE, FALSE)
    manual_a <- ifelse(any(behavior_labels[n] %in% manual_scores), TRUE, FALSE)
    
    # Convert scores to Boolean using the no activity label
    auto_n <- ifelse(any(no_behavior_label %in% auto_scores), TRUE, FALSE)
    manual_n <- ifelse(any(no_behavior_label %in% manual_scores), TRUE, FALSE)
    
    # auto_a
    # manual_a
    # auto_n
    # manual_n
    
    # Score true positives: both methods identified a type of activity
    if(auto_a & manual_a){
      
      true_positive <- 1
      
    } else {
      
      true_positive <- 0
      
    }
    
    # Score false positives: manual scoring identified NOBR or the given type of behavior but ABISSMAL detected a different behavior
    if((!manual_a & auto_a) | (manual_n & !auto_n)){
      
      false_positive <- 1
      
    } else {
      
      false_positive <- 0
      
    }
    
    # Score true negatives: both methods identitfied a different type of activity
    if(auto_n & manual_n){
      
      true_negative <- 1
      
    } else {
      
      true_negative <- 0
      
    }
    
    # Score false negatives: ABISSMAL detected the given behavior but manual scoring identified a different behavior
    if(manual_a & !auto_a){
      
      false_negative <- 1
      
    } else {
      
      false_negative <- 0
      
    }
    
    return(
      data.frame(
        unique_video_recording_event = unique_videos[i],
        behavior_label = behavior_labels[n],
        true_positive = true_positive,
        false_positive = false_positive,
        true_negative = true_negative,
        false_negative = false_negative
      )
    )
    
    
  }))
  
}))

# There should be 4 rows for each of the unique video recording events, looks good
glimpse(tp_fp_tn_fn)
length(unique_videos) * length(behavior_labels) == nrow(tp_fp_tn_fn)

```

Calculate precision, recall, sensitivity, and specificity of activity detection by behavioral activity.
```{r}

tp_fp_tn_fn_sum <- tp_fp_tn_fn %>% 
  group_by(behavior_label) %>% 
  dplyr::summarise(
    tps = sum(true_positive),
    fps = sum(false_positive),
    tns = sum(true_negative),
    fns = sum(false_negative)
  ) %>% 
  ungroup()

tp_fp_tn_fn_sum

# Precision across behaviors
precision_ind <- sapply(1:length(behavior_labels), function(i){
  
  precision(X = tp_fp_tn_fn_sum[grep(behavior_labels[i], tp_fp_tn_fn_sum$behavior_label), ], tps_col_nm = "tps", fps_col_nm = "fps")
  
})

precision_ind

# Sensitivity across behaviors
sensitivity_ind <- sapply(1:length(behavior_labels), function(i){
  
  sensitivity(X = tp_fp_tn_fn_sum[grep(behavior_labels[i], tp_fp_tn_fn_sum$behavior_label), ], tps_col_nm = "tps", fns_col_nm = "fns")
  
})

sensitivity_ind

# Specificity across behaviors
specificity_ind <- sapply(1:length(behavior_labels), function(i){
  
  specificity(X = tp_fp_tn_fn_sum[grep(behavior_labels[i], tp_fp_tn_fn_sum$behavior_label), ], tns_col_nm = "tps", fps_col_nm = "fns")
  
})

specificity_ind

# Note that sensitivity and specificity are not exactly the same here, given the way that false positives and negatives were defined

data.frame(
  behavior_label = behavior_labels,
  precision = precision_ind,
  sensitivity = sensitivity_ind,
  specificity = specificity_ind
)

# Note that the subsample of videos used for code development did not contain perching events
#   behavior_label precision sensitivity specificity
# 1           PERC      0.00        0.00        0.00
# 2           ENTR     42.86       60.00       60.00
# 3           EXIT     25.00       16.67       16.67
# 4           INSC     97.78       88.00       88.00

```
